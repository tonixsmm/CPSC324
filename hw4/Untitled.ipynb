{"cells": [{"cell_type": "markdown", "id": "a4501d6b-d223-4a1f-8c70-aa9c7803849e", "metadata": {}, "source": "Set up a google cloud storage bucket where your raw files are hosted:"}, {"cell_type": "code", "execution_count": 1, "id": "d25b8e0c-570c-4d26-9caf-6bfae73215b8", "metadata": {}, "outputs": [], "source": "PROJECT=!gcloud config get-value project\nPROJECT=PROJECT[0]\nBUCKET = PROJECT + '-dsongcp'\nimport os\nos.environ['BUCKET'] = PROJECT + '-dsongcp'"}, {"cell_type": "markdown", "id": "d994cffc-584a-4963-9315-edf99e30f333", "metadata": {}, "source": "Create a spark session using the following code block:"}, {"cell_type": "code", "execution_count": 2, "id": "a61cbc12-0237-4cc2-a7a3-c20940a0e1c0", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/04/04 05:22:47 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n24/04/04 05:22:47 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n24/04/04 05:22:47 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n24/04/04 05:22:47 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "from pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nsc = SparkContext('local', 'logistic')\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Logistic regression w/ Spark ML\") \\\n    .getOrCreate()"}, {"cell_type": "markdown", "id": "6732e3eb-492b-4232-bda9-984c16fcea2e", "metadata": {}, "source": "### Create a Spark DataFrame"}, {"cell_type": "code", "execution_count": 3, "id": "6ff8d61d-b67d-42fe-8bd2-9c8a2b042fca", "metadata": {}, "outputs": [], "source": "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\nfrom pyspark.mllib.regression import LabeledPoint"}, {"cell_type": "markdown", "id": "14f9ec9a-56f9-4fbf-b63f-4540984aad8d", "metadata": {}, "source": "Read the dataset"}, {"cell_type": "code", "execution_count": 4, "id": "ada0334e-ba77-40ff-915c-00a14a1538b4", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "traindays = spark.read \\\n    .option(\"header\", \"true\") \\\n    .csv('gs://{}/flights/trainday.csv'.format(BUCKET))\ntraindays.createOrReplaceTempView('traindays')"}, {"cell_type": "markdown", "id": "fad4482b-a882-4082-86c7-de96780d37cd", "metadata": {}, "source": "Create a SparkSQL view"}, {"cell_type": "code", "execution_count": 5, "id": "84513f61-4157-49d1-9750-6e0bd06f2b6c", "metadata": {}, "outputs": [], "source": "traindays.createOrReplaceTempView('traindays')"}, {"cell_type": "code", "execution_count": 6, "id": "6fe2431d-82de-4b8e-b5b2-28fcf547bf60", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+------------+\n|   FL_DATE|is_train_day|\n+----------+------------+\n|2015-01-01|        True|\n|2015-01-02|       False|\n|2015-01-03|       False|\n|2015-01-04|        True|\n|2015-01-05|        True|\n+----------+------------+\n\n"}], "source": "spark.sql(\"SELECT * from traindays LIMIT 5\").show()"}, {"cell_type": "code", "execution_count": 7, "id": "3797f7b3-8ad8-49ac-b137-369cd591a6ce", "metadata": {}, "outputs": [], "source": "inputs = 'gs://{}/flights/tzcorr/all_flights-*'.format(BUCKET)"}, {"cell_type": "markdown", "id": "2204f71f-747d-4802-a13c-6501759e468e", "metadata": {}, "source": "Read the data into Spark SQL from the input file you created:"}, {"cell_type": "code", "execution_count": 8, "id": "a3924768-4747-459d-9ee9-1294c9e4ec16", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "flights = spark.read.json(inputs)\nflights.createOrReplaceTempView('flights')"}, {"cell_type": "code", "execution_count": 9, "id": "37519762-4ee3-425b-98b8-01773b976ec5", "metadata": {}, "outputs": [], "source": "trainquery = \"\"\"\nSELECT\n  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\n  t.is_train_day == 'True'\n\"\"\"\ntraindata = spark.sql(trainquery)"}, {"cell_type": "code", "execution_count": 10, "id": "84109d77-f953-43d9-80ce-fd95a05d8966", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Row(DEP_DELAY=-6.0, TAXI_OUT=18.0, ARR_DELAY=-11.0, DISTANCE='425.00'), Row(DEP_DELAY=-1.0, TAXI_OUT=14.0, ARR_DELAY=-8.0, DISTANCE='425.00')]\n"}], "source": "print(traindata.head(2))"}, {"cell_type": "code", "execution_count": null, "id": "1f402348-a045-4e20-bc38-67c3d3b26386", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 6:=========================================>               (25 + 1) / 34]\r"}], "source": "traindata.describe().show()"}, {"cell_type": "code", "execution_count": null, "id": "a56f1e57-5543-4f2e-ad74-b173cd3dcda4", "metadata": {}, "outputs": [], "source": "trainquery = \"\"\"\nSELECT\n  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\n  t.is_train_day == 'True' AND\n  f.dep_delay IS NOT NULL AND \n  f.arr_delay IS NOT NULL\n\"\"\"\ntraindata = spark.sql(trainquery)\ntraindata.describe().show()"}, {"cell_type": "code", "execution_count": null, "id": "69380819-6710-4a1a-9ebb-e167cfc89a8b", "metadata": {}, "outputs": [], "source": "trainquery = \"\"\"\nSELECT\n  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\n  t.is_train_day == 'True' AND\n  f.dep_delay IS NOT NULL AND \n  f.arr_delay IS NOT NULL\n\"\"\"\ntraindata = spark.sql(trainquery)\ntraindata.describe().show()"}, {"cell_type": "code", "execution_count": null, "id": "c974f19c-9168-4ec7-896f-41a0849dca6d", "metadata": {}, "outputs": [], "source": "def to_example(fields):\n    return LabeledPoint(\\\n              float(fields['ARR_DELAY'] < 15), #ontime? \\\n              [ \\\n                  fields['DEP_DELAY'], \\\n                  fields['TAXI_OUT'],  \\\n                  fields['DISTANCE'],  \\\n              ])"}, {"cell_type": "code", "execution_count": null, "id": "b2034463-72c7-4c2b-b2a2-e6163cbcf980", "metadata": {}, "outputs": [], "source": "examples = traindata.rdd.map(to_example)"}, {"cell_type": "code", "execution_count": null, "id": "f38e6b65-c2e9-48e4-b3d9-0bacd9b959fd", "metadata": {}, "outputs": [], "source": "lrmodel = LogisticRegressionWithLBFGS.train(examples, intercept=True)"}, {"cell_type": "code", "execution_count": null, "id": "b8875ee6-c062-4a99-b15b-5e1566ef2255", "metadata": {}, "outputs": [], "source": "print(lrmodel.weights,lrmodel.intercept)"}, {"cell_type": "markdown", "id": "a10b1abd-6e9f-4e33-9112-a7e0f1ddbe75", "metadata": {}, "source": "This cell returns 1 means it is on time"}, {"cell_type": "code", "execution_count": null, "id": "f2b763e4-1f3a-432b-87e6-ee1ba3dab61e", "metadata": {}, "outputs": [], "source": "print(lrmodel.predict([6.0,12.0,594.0]))"}, {"cell_type": "code", "execution_count": null, "id": "5d8d88aa-d91e-4ead-85c8-c07a83977e02", "metadata": {}, "outputs": [], "source": "print(lrmodel.predict([36.0,12.0,594.0]))"}, {"cell_type": "code", "execution_count": null, "id": "f0345732-cfe3-4845-95ec-30db2cea0484", "metadata": {}, "outputs": [], "source": "lrmodel.clearThreshold()\nprint(lrmodel.predict([6.0,12.0,594.0]))\nprint(lrmodel.predict([36.0,12.0,594.0]))"}, {"cell_type": "code", "execution_count": null, "id": "399179c2-6136-427b-b7c0-915c01216c63", "metadata": {}, "outputs": [], "source": "lrmodel.setThreshold(0.7) \nprint(lrmodel.predict([6.0,12.0,594.0]))\nprint(lrmodel.predict([36.0,12.0,594.0]))"}, {"cell_type": "code", "execution_count": null, "id": "364c8118-75c5-430b-8485-be4dff9b3aa0", "metadata": {}, "outputs": [], "source": "MODEL_FILE='gs://' + BUCKET + '/flights/sparkmloutput/model'\nos.system('gsutil -m rm -r ' + MODEL_FILE)"}, {"cell_type": "code", "execution_count": null, "id": "70ccb6af-a9c4-4837-ad67-793e54ae6c5a", "metadata": {}, "outputs": [], "source": "lrmodel.save(sc, MODEL_FILE)\nprint('{} saved'.format(MODEL_FILE))"}, {"cell_type": "code", "execution_count": null, "id": "f9edaa1d-0de2-44f5-9c18-89aa64f04ac0", "metadata": {}, "outputs": [], "source": "lrmodel = 0\nprint(lrmodel)"}, {"cell_type": "code", "execution_count": null, "id": "95c97a1b-fa24-4e7b-ba77-92fb54e9cf85", "metadata": {}, "outputs": [], "source": "from pyspark.mllib.classification import LogisticRegressionModel\nlrmodel = LogisticRegressionModel.load(sc, MODEL_FILE)\nlrmodel.setThreshold(0.7)"}, {"cell_type": "code", "execution_count": null, "id": "dcc7c37f-69e4-4cc4-9f4e-aee96317d294", "metadata": {}, "outputs": [], "source": "print(lrmodel.predict([36.0,12.0,594.0]))"}, {"cell_type": "code", "execution_count": null, "id": "b04b47e3-0c9a-41df-9382-b89a8b47f834", "metadata": {}, "outputs": [], "source": "print(lrmodel.predict([8.0,4.0,594.0]))"}, {"cell_type": "code", "execution_count": null, "id": "c1e15ced-c501-4332-90fb-a39d2e3451c6", "metadata": {}, "outputs": [], "source": "lrmodel.clearThreshold() # to make the model produce probabilities\nprint(lrmodel.predict([20, 10, 500]))"}, {"cell_type": "code", "execution_count": null, "id": "69b9e2ca-4a44-4aaa-8218-6788e8ce9bad", "metadata": {}, "outputs": [], "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\ndist = np.arange(10, 2000, 10)\nprob = [lrmodel.predict([20, 10, d]) for d in dist]\nsns.set_style(\"whitegrid\")\nax = plt.plot(dist, prob)\nplt.xlabel('distance (miles)')\nplt.ylabel('probability of ontime arrival')"}, {"cell_type": "code", "execution_count": null, "id": "8ecf0ec0-f264-4f90-91aa-26c77e9210ef", "metadata": {}, "outputs": [], "source": "delay = np.arange(-20, 60, 1)\nprob = [lrmodel.predict([d, 10, 500]) for d in delay]\nax = plt.plot(delay, prob)\nplt.xlabel('departure delay (minutes)')\nplt.ylabel('probability of ontime arrival')"}, {"cell_type": "code", "execution_count": null, "id": "31cde6c5-7e24-47c0-b768-b74bd804ad43", "metadata": {}, "outputs": [], "source": "inputs = 'gs://{}/flights/tzcorr/all_flights-*'.format(BUCKET)\nflights = spark.read.json(inputs)\nflights.createOrReplaceTempView('flights')\n\ntestquery = trainquery.replace(\"t.is_train_day == 'True'\",\"t.is_train_day == 'False'\")"}, {"cell_type": "code", "execution_count": null, "id": "acf2a776-b306-4595-a6e2-1ada9ad382d1", "metadata": {}, "outputs": [], "source": "testdata = spark.sql(testquery)\nexamples = testdata.rdd.map(to_example)"}, {"cell_type": "code", "execution_count": null, "id": "7788977f-0514-4417-a7ce-041288c55fbe", "metadata": {}, "outputs": [], "source": "testdata.describe().show()"}, {"cell_type": "code", "execution_count": null, "id": "f172f03b-ed77-4f23-8c7c-2919671c2f7e", "metadata": {}, "outputs": [], "source": "def eval(labelpred):\n    ''' \n        data = (label, pred)\n            data[0] = label\n            data[1] = pred\n    '''\n    cancel = labelpred.filter(lambda data: data[1] < 0.7)\n    nocancel = labelpred.filter(lambda data: data[1] >= 0.7)\n    corr_cancel = cancel.filter(lambda data: data[0] == int(data[1] >= 0.7)).count()\n    corr_nocancel = nocancel.filter(lambda data: data[0] == int(data[1] >= 0.7)).count()\n    \n    cancel_denom = cancel.count()\n    nocancel_denom = nocancel.count()\n    if cancel_denom == 0:\n        cancel_denom = 1\n    if nocancel_denom == 0:\n        nocancel_denom = 1\n    return {'total_cancel': cancel.count(), \\\n            'correct_cancel': float(corr_cancel)/cancel_denom, \\\n            'total_noncancel': nocancel.count(), \\\n            'correct_noncancel': float(corr_nocancel)/nocancel_denom \\\n           }"}, {"cell_type": "code", "execution_count": null, "id": "e29df19b-4d2d-4796-aced-00fc03db8218", "metadata": {}, "outputs": [], "source": "lrmodel.clearThreshold() # so it returns probabilities\nlabelpred = examples.map(lambda p: (p.label, lrmodel.predict(p.features)))\nprint('All flights:')\nprint(eval(labelpred))"}, {"cell_type": "code", "execution_count": null, "id": "5eb5be2d-85d6-45c6-b9e9-660bc90b8eb1", "metadata": {}, "outputs": [], "source": "print('Flights near decision threshold:')\nlabelpred = labelpred.filter(lambda data: data[1] > 0.65 and data[1] < 0.75)\nprint(eval(labelpred))"}, {"cell_type": "code", "execution_count": null, "id": "9bc7ebad-eb65-42df-bb1e-94f967ecba03", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}